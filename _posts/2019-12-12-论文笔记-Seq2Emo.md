---
layout:    post
title:     论文笔记
subtitle:  Seq2Emo for Multi-label Emotion Classification Based on Latent Variable Chains Transformation
date:      2019-12-12
author:     dhx20150812
header-img: img/post-bg-ios9-web.jpg
catalog:   true
mathjax:   true
tags:
    - NLP
    - 文本分类
    - 多标签分类
---

# Seq2Emo for Multi-label Emotion Classification Based on Latent Variable Chains Transformation

> 来自AAAI 2020 [https://arxiv.org/pdf/1911.02147.pdf](https://arxiv.org/pdf/1911.02147.pdf)


## Motivation：

当前很多方法在做文本的情绪识别任务时，都将其建模为一个多标签分类(`Multi-label Classifiction`)问题，然后给网络最后一个输出层指定一个阈值，或者训练多个二分类器。

这样存在一些问题，首先，它忽略了情绪标签之间的关联性。比如，通常来说人们不会同时表达“高兴”和“愤怒”，但很可能“高兴”和“喜爱”会同时出现。

基于此，作者提出了隐变量链(`Latent Variable Chain`)的方法，它建模了情绪标签之间的关联性，同时提出了一个`Seq2Emo`的模型，它在考虑情绪标签之间关联性的同时预测了多个标签。

## Introduction

针对MLC问题的方法通常都含有大量的问题转换(`Problem Transformation`)，假设情绪集合为 $\mathcal{L}=\\{l\_{1},l\_{2},\cdots,l\_{k}\\}$，主要有如下三种：

- Binary Relevance，训练多个独立的二分类器，每个只用来判断一种情绪
- Classifier Chains，训练多个有关联的二分类器，考虑到了情绪标签之间的关联性
- Label Powerset，考虑了所有的标签组合的情况，因此共训练了$2^k$个分类器，当`k`很大时不适用

作者基于深度学习的隐层变量提出了`Latent Variable Chain`的方法，然后基于LVC提出了Seq2Emo这一模型。它可以捕获语义和情绪特征，然后使用双向的LVC来生成label。同时作者还收集了一个新的数据集`Balanced Multi-label Emotional Tweets`(BMLT)。

总结起来，本文的贡献有如下三点：

- 将多标签情绪分类建模为LVC问题
- 提出了新模型Seq2Emo
- 收集了新数据集BMLT


## Overview

本章将系统地介绍下BR和CC变换，同时如何在深度学习方法上使用这两种变换。

### MLC任务

MLC任务的形式化定义如下：给定一个文本 $X=\\{x\_1,x\_2,\dots,x\_n\\}$，其中 $x\_i$ 是一个词，$n$ 为文本的长度。每个文本都对应着一个目标 $Y \subseteq \mathcal{L}$，符号 $\subseteq$ 代表了每个 $Y$ 都包含了 $\mathcal{L}$ 中的多个元素，或为空集 $Y=\emptyset$。

MLC模型的目标是学习到一个条件分布 $\mathcal{P}(Y \mid X)$，$Y$ 是一个集合，其中的元素个数不一定是1

### BR Transformation

在BR的变换下，可以使用多个独立的二分类器来分别处理每种情绪。首先，目标 $Y^{b}=\left(y\_{1}, y\_{2}, \cdots, y\_{k}\right)$ 是一个0/1向量，当label set的大小为`k`时，需要训练`k`个独立的分类器。

设BR变换的分类器为 $C\_{j}^{B}(j \in[1 \cdots k])$。其中，分类器 $C_{j}^{B}$ 只用作生成 $y\_i$。换言之，$C\_j^B$ 需要学习到概率分布 $\mathcal{P}\left(y\_{i} \mid X\right)$，$Y^b$ 是通过所有的 k 个分类器共同得到的。

传统的分类器，如 SVM、Naive Bayes 等都可以用作 BR 变换的分类器，然而深度学习的方法不用`k`个分类器，它可以使用全连接层将隐层向量表示直接投影到标签层。全连接层的作用就是一个分类器，它采用编码器的输出作为输入，产生分类结果。那么`k`个分类器就可以共享编码器，然后使用不同的全连接层。

BR变换的分类器有两种变体，一种是在全连接层的输出有两个cell，另一种是只有一个cell。如下图所示

<img src="https://note.youdao.com/yws/api/personal/file/WEBb588927fc1f025fc9db965843f47c4dc?method=download&shareKey=1f62f0e3439b27bb310bab388b6c6cc4" alt="image-20191128154600703" style="zoom:45%;" />

两种变体的处理分别如下：

-   如上图左边所示，两个cell的输出经过softmax层，两个输出记作 $b_j^1$ 和 $b_j^2$，有 $y_{i} \triangleq \mathbb{1}\left(b_{j}^{0}<b_{j}^{1}\right)$

-   如上图右侧所示，引入阈值超参 $\tau$，输出经过sigmoid标准化，有$y_{i} \triangleq \mathbb{1}\left(b_{j}^{r}>\tau\right)$



### CC Transformation

同样的，CC变换也需要`k`个分类器。给定分类器 $C_j^C, j \in [1...k]$ ，原始的CC变换进行了`k`个二分类，每次的分类都基于上次的输出。使用二进制表示$Y^b$，这个变换可以被表示为如下的递归过程：

$$
y_j=C_j^C(X, y_{j-1})
$$

进入深度学习的时代之后，seq2seq模型被应用到各类任务上。它与CC变换的过程十分相似。它包括了两部分，一个Encoder和一个Decoder。

其中，Encoder将序列信息$X$压缩为向量或者向量表示：

$$
\boldsymbol{v}=Encoder(X)
$$

给定$\boldsymbol{v}$，decoder使用如下标签来预测目标$Y^b$：

$$
y_i=Decoder(\boldsymbol{v}, y_{j-1})
$$

CC变换有一个严重的问题。由于在测试阶段我们并不知道上一时刻的真实标签 $y_{j-1}$，如果使用预测出的 $\hat{y}\_{j-1}$，则会导致训练阶段和测试阶段的不一致性。这就是`exposure bias`问题。



## Method

模型整体分为Encoder和Decoder，如图所示——

![image-20191128163021357](https://note.youdao.com/yws/api/personal/file/WEB021c228f094a5bd1c3c6a27954098a9d?method=download&shareKey=dc79c1ec555648fb47801ce49f51bffc)

### Encoder

Encoder端使用了多层的双向LSTM，它将输入序列 $X=[x_1, x_2,\cdots,x_n]$。作者结合使用了Glove和ELMo来更好地捕获上下文的语义信息。

#### Glove和ELMo

`Glv`是一个预训练的Glove模型，由Glove生成的词向量可以被表示为`Glv(x_t)`。`Glv`是一个矩阵，维度为$\|V\| \times D_{G}$。其中 $D_G$是Glove的Embedding size。$\|V\|$是词表大小。

同时，`ELMo`模型将句子 $X$ 作为输入，生成一个矩阵，维度是 $\|n\| \times D_{E}$。其中，$D_E$ 是 ELMo的embedding size，$\|n\|$ 是句子长度。

于是，$x_t$ 可表示分别为 $Glv(X_t)$ 和 $Elm_t^X$ 。

#### LSTM Encoder

在得到单词的向量表示之后，我们将两个词向量拼接，然后使用多层的双向LSTM来编码输入信息：

$$
h_{t}^{E}, c_{t}^{E}=\mathrm{bi}-\mathrm{LSTM}^{E}\left(\left[G l v\left(X_{t}\right) ; E l m_{t}^{X}\right],\left[h_{t-1}^{E} ; c_{t-1}^{E}\right]\right)
$$

$h_t^E$ 和 $c^E_t$ 分别代表了LSTM网络 $t$ 时刻的隐层状态和细胞状态。

#### Global Attention

将LSTM顶层的隐层状态记作 $\overline{\boldsymbol{h}}^{E}=\left[\bar{h}\_{1}^{E}, \bar{h}\_{2}^{E}, \cdots, \bar{h}\_{n}^{E}\right]$，作者在前向和后向解码时采用了一个单层单向的LSTM。记 $h\_t^D$ 是解码器Decoder在 $t$ 时刻的隐层状态。它会沿着如下过程更新：

$$
h_{t}^{D} \rightarrow \boldsymbol{\alpha}_{t} \rightarrow C T X_{t} \rightarrow \tilde{h}_{t}^{D}
$$

其中，$\alpha\_{t}$ 是attention分数的向量，$CTX\_t$ 是上下文向量，在每一时刻都会更新。它是编码器输出 $\bar{h}^{E}$ 和attention分数 $\alpha\_t$ 的加权和。解码器隐层状态 $h\_t^D$ 的更新过程如下所示：

$$
\begin{aligned} \tilde{h}_{t}^{D} &=\tanh \left(W_{c}\left[C T X_{t} ; h_{t}^{D}\right]\right) \\ C T X_{t} &=\frac{\sum \alpha_{t} \bar{h}^{E}}{\sum \alpha_{t}} \\ \alpha_{t}(i) &=\frac{\exp \left(\text { score }\left(h_{t}^{D}, \bar{h}_{t}^{E}\right)\right)}{\sum_{j=1}^{n} \exp \left(\operatorname{score}\left(h_{t}^{D}, \bar{h}_{j}^{E}\right)\right)} \\ \text { score }\left(h_{t}^{D}, \bar{h}_{i}^{E}\right) &=h_{t}^{D \top} W_{a} \bar{h}_{i}^{E} \end{aligned}
$$

### Decoder

解码器的设计是Seq2Emo模型的核心。在解码器中，作者引入了DeepMoji编码，因为它可以带来情绪的语义维度。将其记作 $Moji_X = DeepMoji(X)$。同时，作者在decoder端也采用了双向LSTM，对其单向来说，隐层状态的更新如下：

$$
h_{t}^{D}, c_{t}^{D}=\operatorname{LSTM}^{D}\left(\left[s_{t}, F C_{t}^{m}\left(\operatorname{Moji}_{X}\right)\right],\left[\tilde{h}_{t-1}^{D} ; c_{t-1}^{D}\right]\right)
$$

将前向和后向的隐层状态分别记作 $\vec{h}\_{t}^{D}$和 $\overleftarrow{h}\_{t}^{D}$ ，将其拼接后输入全连接层，有

$$
y_{t}=F C_{t}^{o}\left(\left[\vec{h}_{t}^{D} ; \overleftarrow{h}_{t}^{D}\right]\right)
$$


## 实验

### Datesets

实验采用了三个数据集，SemEval-18、CBET和BMET。他们的标签分布如下——

![image-20191202105449064](https://note.youdao.com/yws/api/personal/file/WEB86c99172e8ed82d4ea3d98cb8d70d52a?method=download&shareKey=3cd0dbe286191a8a4a79d9adbc09b65e)

可以看到，CBET大部分都是单标签的。

### Metrics

评价多标签分类优劣的准则有如下三种——Jaccard index、Hamming loss和Micro F1。

其中，Jaccard index的计算如下——

$$
J=\frac{1}{N} \sum_{i=1}^{N} \frac{\left|Y_{i}^{t e} \cap \hat{Y}_{i}^{t e}\right|}{\left|Y_{i}^{t e} \cup \hat{Y}_{i}^{t e}\right|}
$$

$Y\_i^{te}$ 代表数据集中的真实的标签集合，$\hat{Y}\_{i}^{t e}$ 是模型预测的标签集合。

### Results

最终实验的结果如下——

<img src="https://note.youdao.com/yws/api/personal/file/WEB7bd28b48f9ae95855b3d622c510d9e27?method=download&shareKey=eba5d912c62c29449ba77fb6ba8aef04" alt="image-20191202105113742" style="zoom:150%;" />

从上图可以看到，作者提出的Seq2Emo-LD在两个数据集上都取得了最好的效果。而在CBET数据集上，Binary-SLD取得了最好的效果，可能是因为该数据集样本过少，导致深度学习模型的泛化能力不强。

## 数据集的采集

数据集的采集步骤基本遵循了[Abdul-Mageed和Ungar等人的工作](https://www.aclweb.org/anthology/P17-1067.pdf)，大概有如下步骤：

1.  爬取约40亿条推特，然后过滤掉非英文的推特
2.  手动定义46个hashtag对应着9种情绪（与CBET相同）
3.  根据2过滤推特，保留那些至少有两种情绪的推特
4.  删除"love"的情绪，因为87%的推特都包含这一情绪
5.  删除"guilt"和"disgust"，他们只在不到1%的推特上同时出现
6.  只保留文本长度大于3小于50的推特
7.  删除爬取时所用到的hashtag
8.  将emoji表情转换为文本表示

将数据集分为多标签和单标签，并且计算多标签部分的分布，然后从单标签部分采样来补充，使其达到分布均衡。

最终用来提取情绪的hashtag如下——

<img src="https://note.youdao.com/yws/api/personal/file/WEBe162ac57973c387f9ae5901c2faafdf7?method=download&shareKey=2dca63c1c55dc822b3a6b38057ac3cd9" alt="image-20191202105916801" style="zoom: 50%;" />
